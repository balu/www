#+TITLE: Compilers
#+AUTHOR: Balagopal Komarath

* Policy

Attend lectures only if you want to. You are expected to keep up to
date on the discussions that happen during lectures and labs.

** Evaluation

| Assessment            | Percentage | Remarks                     |
|-----------------------+------------+-----------------------------|
| Lab quizzes           |         30 | Small programming exercises |
| Semester-long project |         50 | Team of 4.                  |
| Mid-semester exam     |         10 |                             |
| End-semester exam     |         10 |                             |

** Resources

There is no textbook. Follow the lectures. Code a lot. Read necessary
theory.

[[https://craftinginterpreters.com/][Bob Nystrom's Crafting Interpreters]] is a good book. I will disagree
with this book on some of the topics.

* Lectures

** Calculator back-end

You have all used compilers and you know what they do. In this course,
we will build one and explore how compilers are organized and the
relevant algorithms.

The most common data structure in a compiler is a tree and the most
common algorithm, the post-order traversal. To see why, let us build a
simple calculator. It accepts expressions and evaluates them. What is
the best way to represent an expression like =2 + 3*5= in a computer?
#+begin_example

       +
      / \
     2   *
        / \
       3   5

#+end_example
Yes. A tree. How would you evaluate this expression? Evaluate the left
sub-tree, then the right sub-tree, then add the results. That is, a
post-order traversal.

The front-end of the compiler has to take the string =2 + 3*5= and
build this tree. This is done using two classes of algorihms called
lexing and parsing, which correspond to DFAs and CFGs respectively. We
will see this part later. First, we will build the back-end for the
compiler. It takes trees as input and evaluates them.

First, let us define some classes in Python to represent expression
trees.
#+begin_src python :session leroy :python ".compilers/.venv/bin/python" :results none
  from dataclasses import dataclass

  class AST:
      pass

  @dataclass
  class BinOp(AST):
      op: str
      left: AST
      right: AST

  @dataclass
  class Number(AST):
      val: str
#+end_src

The tree for the previous expression can be created so:
#+begin_src python :session leroy :results output
  expr_t1 = BinOp("+", Number("2"), BinOp("*", Number("3"), Number("5")))
  print(expr_t1)
#+end_src

#+RESULTS:
: BinOp(op='+', left=Number(val='2'), right=BinOp(op='*', left=Number(val='3'), right=Number(val='5')))

Now, let us write an evaluator. This function should take the tree as
input and produce a number.
#+begin_src python :session leroy :results none
  def e(tree: AST) -> int:
      match tree:
          case Number(v): return int(v)
          case BinOp("+", l, r): return e(l) + e(r)
          case BinOp("*", l, r): return e(l) * e(r)
#+end_src
Let us test it by evaluating our sample expression.
#+begin_src python :session leroy :results value
  e(expr_t1)
#+end_src

#+RESULTS:
: 17

Yay! Now, extend this small program to make what you think a real
calculator should be.

** Calculator front-end

The front-end of the calculator should take a string as input and
return the corresponding expression tree. We split this into a lexer
and a parser.

The lexer converts a stream of characters into a stream of
tokens. First, we define the tokens of our language.
#+begin_src python :session leroy :results none
  class Token:
      pass

  @dataclass
  class NumberToken(Token):
      v: str

  @dataclass
  class OperatorToken(Token):
      o: str
#+end_src

Now, the lexer can produce the token stream.
#+begin_src python :session leroy :results none
  from collections.abc import Iterator
  def lex(s: str) -> Iterator[Token]:
      i = 0
      while True:
          while i < len(s) and s[i].isspace():
              i = i + 1

          if i >= len(s):
              return

          if s[i].isdigit():
              t = s[i]
              i = i + 1
              while i < len(s) and s[i].isdigit():
                  t = t + s[i]
                  i = i + 1
              yield NumberToken(t)
          else:
              match t := s[i]:
                  case '+' | '*':
                      i = i + 1
                      yield OperatorToken(t)
#+end_src

Let us test our lexer with our sample expression.
#+begin_src python :session leroy :results output
  for t in lex("2 + 3*5"):
      print(t)
#+end_src

#+RESULTS:
: NumberToken(v='2')
: OperatorToken(o='+')
: NumberToken(v='3')
: OperatorToken(o='*')
: NumberToken(v='5')

The parser takes the token stream as input and produces the AST.
#+begin_src python :session leroy :results none
  from collections.abc import Iterator
  def parse(s: str) -> AST:
      from more_itertools import peekable
      t = peekable(lex(s))

      def parse_add():
          ast = parse_mul()
          while True:
              match t.peek(None):
                  case OperatorToken('+'):
                      next(t)
                      ast = BinOp('+', ast, parse_mul())
                  case _:
                      return ast

      def parse_mul():
          ast = parse_atom()
          while True:
              match t.peek(None):
                  case OperatorToken('*'):
                      next(t)
                      ast = BinOp("*", ast, parse_atom())
                  case _:
                      return ast

      def parse_atom():
          match t.peek(None):
              case NumberToken(v):
                  next(t)
                  return Number(v)

      return parse_add()
#+end_src

#+RESULTS:

Let us test the parser for some expressions.
#+begin_src python :session leroy :results output
  print(parse("2"))
  print(parse("2+3"))
  print(parse("2+3*5"))
#+end_src

#+RESULTS:
: Number(val='2')
: BinOp(op='+', left=Number(val='2'), right=Number(val='3'))
: BinOp(op='+', left=Number(val='2'), right=BinOp(op='*', left=Number(val='3'), right=Number(val='5')))

To put the front-end and back-end together, we just have to compose
~parse~ and ~e~.
#+begin_src python :session leroy :results output
  print(e(parse("2 + 3*5")))
#+end_src

#+RESULTS:
: 17

Now is the time to extend this into a more useful calculator. I
suggest adding the following features.
- All usual arithmetic operators, including the unary negation.
- Parenthesis for grouping.
- Use a proper number type for evaluation.
- Error-handling in the front-end.

** Conditional expressions

We will implement a conditional expression of the form ~if a then b
else c end~. To do this, we need the following additions:
- Lexing: Add support for keywords like ~if~.
- Parsing: Add support for conditional expressions. This has a lower
  precedence than arithmetic.
- Evaluation: Modify the post-order traversal to conditionally
  traverse sub-trees.

As before, we will start by defining the AST node.
#+begin_src python :results none :session leroy
  @dataclass
  class If(AST):
      c: AST
      t: AST
      e: AST
#+end_src
We will use ~BinOp~ for comparison operators.

We want to handle expressions like:
#+begin_src python :session leroy :results none
  expr_t2 = If(BinOp("<", Number("2"), Number("3")), Number("0"), Number("1"))
  expr_t3 = If(BinOp("<", Number("3"), Number("2")), Number("0"), Number("1"))
#+end_src

The evaluator is:
#+begin_src python :results none :session leroy
  def e(tree: AST) -> int | bool:
      match tree:
          case Number(v): return int(v)
          case BinOp("+", l, r): return e(l) + e(r)
          case BinOp("*", l, r): return e(l) * e(r)
          case BinOp("<", l, r): return e(l) < e(r)
          case If(cond, then, else_):
              if e(cond):
                  return e(then)
              else:
                  return e(else_)
#+end_src

Let us test it with our sample expression.
#+begin_src python :session leroy :results output :exports both
  print(e(expr_t2))
  print(e(expr_t3))
#+end_src

#+RESULTS:
: 0
: 1

Now, we will modify the front-end to allow the programmer to input
these expressions. We will need a token type for keywords.
#+begin_src python :results none :session leroy
  @dataclass
  class KeywordToken(Token):
      w: str
#+end_src

In ~lex~, if the first character is a letter, then we will try and
form a keyword token. We should also handle comparison operators.
#+begin_src python :session leroy :results none
  from collections.abc import Iterator
  def lex(s: str) -> Iterator[Token]:
      i = 0
      while True:
          while i < len(s) and s[i].isspace():
              i = i + 1

          if i >= len(s):
              return

          if s[i].isalpha():
              t = s[i]
              i = i + 1
              while i < len(s) and s[i].isalpha():
                  t = t + s[i]
                  i = i + 1
              # XXX: Should check here whether we got a valid keyword.
              yield KeywordToken(t)
          elif s[i].isdigit():
              t = s[i]
              i = i + 1
              while i < len(s) and s[i].isdigit():
                  t = t + s[i]
                  i = i + 1
              yield NumberToken(t)
          else:
              match t := s[i]:
                  case '+' | '*' | '<':
                      i = i + 1
                      yield OperatorToken(t)
#+end_src

Let us see what tokens are produced by our new lexer.
#+begin_src python :results output :session leroy :exports both
  for t in lex("if 2 < 3 then 0 else 1 end"):
      print(t)
#+end_src

#+RESULTS:
: KeywordToken(w='if')
: NumberToken(v='2')
: OperatorToken(o='<')
: NumberToken(v='3')
: KeywordToken(w='then')
: NumberToken(v='0')
: KeywordToken(w='else')
: NumberToken(v='1')
: KeywordToken(w='end')

It looks fine. Now, we move on to parsing.

While parsing, we will peek at the first token. If it is the keyword
~if~, then we will try to parse an ~if~ expression. If it begins with
another token, we will try and parse an arithmetic expression.

#+begin_src python :session leroy :results none
  class ParseError(Exception):
      pass

  def parse(s: str) -> AST:
      from more_itertools import peekable
      t = peekable(lex(s))

      def expect(what: Token):
          if t.peek(None) == what:
              next(t)
              return
          raise ParseError

      def parse_if():
          match t.peek(None):
              case KeywordToken("if"):
                  next(t)
                  cond = parse_if()
                  expect(KeywordToken("then"))
                  then = parse_if()
                  expect(KeywordToken("else"))
                  else_ = parse_if()
                  expect(KeywordToken("end"))
                  return If(cond, then, else_)
              case _:
                  return parse_cmp()

      def parse_cmp():
          l = parse_add()
          if t.peek(None) == OperatorToken('<'):
              next(t)
              r = parse_add()
              return BinOp('<', l, r)
          else:
              return l

      def parse_add():
          ast = parse_mul()
          while True:
              match t.peek(None):
                  case OperatorToken('+'):
                      next(t)
                      ast = BinOp('+', ast, parse_mul())
                  case _:
                      return ast

      def parse_mul():
          ast = parse_atom()
          while True:
              match t.peek(None):
                  case OperatorToken('*'):
                      next(t)
                      ast = BinOp("*", ast, parse_atom())
                  case _:
                      return ast

      def parse_atom():
          match t.peek(None):
              case NumberToken(v):
                  next(t)
                  return Number(v)

      return parse_if()
#+end_src

Let us test it on a sample.
#+begin_src python :session leroy :results output :exports both
  print(parse("if 2 < 3 then 0+5 else 1*6 end"))
#+end_src

#+RESULTS:
: If(c=BinOp(op='<', left=Number(val='2'), right=Number(val='3')), t=BinOp(op='+', left=Number(val='0'), right=Number(val='5')), e=BinOp(op='*', left=Number(val='1'), right=Number(val='6')))

** Variables

Consider the following emacs lisp example:
#+begin_src emacs-lisp :results output :exports both
  (defvar v 1)
  
  (defun foo ()
    (princ v))

  (defun bar ()
    (let ((v 10))
      (foo)))

  (bar)
#+end_src

#+RESULTS:
: 10

Compare it with the following Python code that is the same except in
the scoping of variables.
#+begin_src python :python "python3" :results output :exports both
  v = 1

  def foo():
      print(v)

  def bar():
      v = 10
      foo()

  bar()
#+end_src

#+RESULTS:
: 1

The ~v~ in ~foo()~ refers to the global ~v~ in Python. The ~v~ in
~bar()~ is local to that function and cannot escape unless it is
passed as an argument to ~foo()~. This is called lexical scoping. The
association of variable use to declaration is determined by program
text. Emacs lisp uses dynamic scoping, where the association is
determined by the state of execution.

#+begin_src emacs-lisp :results output :exports both
  (defvar v 1)

  (defun foo ()
    (print v))

  (defun bar (a)
    (if a (let ((v 10)) (foo)) (foo)))

  (bar nil)
  (bar t)
#+end_src

#+RESULTS:
: 
: 1
: 
: 10

In the following example, observe that ~foo()~ picks up either the
global ~v~ or the ~v~ local to ~bar()~ depending on the argument to
~bar()~.

#+RESULTS:
: 
: 1
: 
: 10

Modern languages all use lexical scoping by default. But, an option to
have dynamic variables is also nice.

** Dynamic scoping

Implementing dynamic scoping is easy. During evaluation, we keep a
stack that maps variable names to values. Each variable declaration
pushes an entry into this stack and each variable use looks for the
variable in this stack from top to bottom. This will pick-up the most
recently declared variable of the same name.

If your language has no functions, then there is no difference between
lexical and dynamic scoping.

The following class represents the programming construct ~let v be e
in f end~ which binds the value ~e~ to ~v~ and then evaluates
~f~. Here, ~v~ must be a valid identifier and ~e~ and ~f~ must be
expressions.
#+begin_src python :session leroy :results none
  @dataclass
  class Let(AST):
      v: str
      e: AST
      f: AST
#+end_src

We also need a class for occurences of variables within expressions.
#+begin_src python :session leroy :results none
  @dataclass
  class Var(AST):
      v: str
#+end_src

The evaluation now requires a stack in addition to the AST. Usually,
this stack is called the environment.
#+begin_src python :session leroy :results none
  def lookup(env, v):
      for u, uv in reversed(env):
          if u == v:
              return uv
      raise ValueError("No value found.")

  def e(t: AST, env = None) -> int:
      if env is None: env = []

      match t:
          case Var(v):
              return lookup(env, v)
          case Let(v, x, y):
              vv = e(x, env)
              env.append((v, vv))
              yv = e(y, env)
              env.pop()
              return yv
          case Number(s):
              return int(s)
          case BinOp("+", l, r):
              return  e(l, env) + e(r, env)
      assert False
#+end_src

Let us create two sample ASTs and test them.
#+begin_src python :session leroy :results none
  expr_t4 = Let("a", Number("3"), BinOp("+", Var("a"), Var("a")))
  expr_t5 = Let("a", Number("3"),
		Let("b", BinOp("+", Var("a"), Number("2")),
		    BinOp("+", Var("a"), Var("b"))))
#+end_src

#+begin_src python :session leroy :results output :exports both
  print(e(expr_t4))
  print(e(expr_t5))
#+end_src

#+RESULTS:
: 6
: 8

Now, we will add the surface syntax which will look like ~let a be 3
in a + a end~. I prefer keywords such as ~be~ instead of symbols such
as ~=~ or ~:=~ as words are easier to type for me. However, when
choosing a keyword, we have to ensure that it is a word that will not
be used often as variable names. The word ~be~ is not a common
variable name. So this choice is fine.

The lexer should have variable tokens.
#+begin_src python :session leroy :results none
  @dataclass
  class VarToken(Token):
      v: str
#+end_src

After lexing a word, we have to lookup whether it is a keyword. If it
is, then we return a keyword token. Otherwise, it is a variable.
#+begin_src python :session leroy :results none
  from collections.abc import Iterator

  def lex(s: str) -> Iterator[Token]:
      i = 0
      while True:
          while i < len(s) and s[i].isspace():
              i = i + 1

          if i >= len(s):
              return

          if s[i].isalpha():
              t = s[i]
              i = i + 1
              while i < len(s) and s[i].isalpha():
                  t = t + s[i]
                  i = i + 1
              if t in { "let", "be", "in", "end" }:
                  yield KeywordToken(t)
              else:
                  yield VarToken(t)
          elif s[i].isdigit():
              t = s[i]
              i = i + 1
              while i < len(s) and s[i].isdigit():
                  t = t + s[i]
                  i = i + 1
              yield NumberToken(t)
          else:
              match t := s[i]:
                  case '+' | '*' | '<':
                      i = i + 1
                      yield OperatorToken(t)
#+end_src

Let us test the lexer.
#+begin_src python :session leroy :results output :exports both
  for t in lex("let a be 3 in a + a end"):
      print(t)
#+end_src

#+RESULTS:
: KeywordToken(w='let')
: VarToken(v='a')
: KeywordToken(w='be')
: NumberToken(v='3')
: KeywordToken(w='in')
: VarToken(v='a')
: OperatorToken(o='+')
: VarToken(v='a')
: KeywordToken(w='end')

The parser tries to parse a ~let~ expression if it observes the token
~let~ at the beginning.
#+begin_src python :session leroy :results none
  class ParseError(Exception):
      msg: str

  def parse(s: str) -> AST:
      from more_itertools import peekable
      t = peekable(lex(s))

      def expect(what: Token):
          if t.peek(None) == what:
              next(t)
              return
          raise ParseError(f"Expected {what}")

      def parse_let():
          match t.peek(None):
              case KeywordToken("let"):
                  next(t)
                  vt = next(t)
                  expect(KeywordToken("be"))
                  e = parse_let()
                  expect(KeywordToken("in"))
                  f = parse_let()
                  expect(KeywordToken("end"))
                  return Let(vt.v, e, f)
              case _:
                  return parse_add()

      def parse_add():
          ast = parse_atom()
          while True:
              match t.peek(None):
                  case OperatorToken('+'):
                      next(t)
                      ast = BinOp('+', ast, parse_atom())
                  case _:
                      return ast

      def parse_atom():
          match t.peek(None):
              case NumberToken(v):
                  next(t)
                  return Number(v)
              case VarToken(v):
                  next(t)
                  return Var(v)

      return parse_let()
#+end_src

#+begin_src python :session leroy :results output :exports both
  print(e(parse("let a be 3 in a + a end")))
  print(e(parse("let a be 3 in let b be a + 2 in a + b end end")))
#+end_src

#+RESULTS:
: 6
: 8

** Functions

Let us implement functions. We need two new AST nodes. One for
defining and another for calling functions.

#+begin_src python :session leroy :results none
  @dataclass
  class Fun(AST):
      n: str # Name of function
      a: str # Parameter
      b: AST # Body
      e: AST # Function calls here

  @dataclass
  class Call(AST):
      n: str # Name of function
      a: AST # Argument
#+end_src

We want to write code such as:
#+begin_src python :session leroy :results none
  expr_t6 = """
  fun dbl(a) is a + a
  in
    dbl(2) + dbl(3)
  end
  """
#+end_src
to define a function and call it two times with two different
arguments. It corresponds to the AST:
#+begin_src python :session leroy :results none
  expr_t6ast = Fun (
      "dbl",
      "a",
      BinOp("+", Var("a"), Var("a")),
      BinOp("+", Call("dbl", Number("2")), Call("dbl", Number("3")))
  )
#+end_src

First, the evaluation. When a function is defined, we parse and put
its body into an environment. When it is called, we evaluate the body
in an environment where the parameter is bound to the argument.
#+begin_src python :session leroy :results none
  def lookup(env, v):
      for u, uv in reversed(env):
          if u == v:
              return uv
      raise ValueError("No value found.")

  def e(t: AST, env = None) -> int:
      if env is None: env = []

      match t:
          case Let(v, x, y):
              vv = e(x, env)
              env.append((v, vv))
              yv = e(y, env)
              env.pop()
              return yv
          case Var(v):
              return lookup(env, v)
          case Fun(f, a, b, c):
              env.append((f, (a, b)))
              x = e(c, env)
              env.pop()
              return x
          case Call(f, x):
              a, b = lookup(env, f)
              env.append((a, e(x, env)))
              y = e(b, env)
              env.pop()
              return y
          case Number(s):
              return int(s)
          case BinOp("+", l, r):
              return  e(l, env) + e(r, env)
#+end_src

Let us test this on the hand-crafted AST.
#+begin_src python :session leroy :results output :exports both
  print(e(expr_t6ast))
#+end_src

#+RESULTS:
: 10

The modifications to the front-end are straight-forward. It is left as
an exercise.

** Functions with static scoping

We want to create an AST for the following code:
#+begin_src
  let x be 5 in
    fun f(y) is x in
      fun g(z) is let x be 6 in f(z) end in
        g(0)
      end
    end
  end
#+end_src
and demonstrate that it evaluates to 6 with dynamic scoping. With
static scoping, it would have evaluated to 5.

To implement static scoping. We add a ~resolve()~ pass that renames
variables so that each variable has a unique name. For this, we
redefine the ~Variable~ class.
#+begin_src python :session leroy :results none
  @dataclass
  class Var(AST):
      v: str
      i: int = None
#+end_src
where the ~i~ field holds the integer that will help us resolve
variables to bindings.

We redefine some of the AST nodes to store ~Var~ instead of just a
string.
#+begin_src python :session leroy :results none
  @dataclass
  class Let(AST):
      x: AST # Always a Var
      e: AST
      f: AST

  @dataclass
  class Fun(AST):
      f: str # Functions are second-class.
      x: AST # Parameter.
      b: AST
      e: AST
#+end_src

The AST for the above expression is:
#+begin_src python :session leroy :results none
  expr_t7ast = Let (
      Var("x"),
      Number("5"),
      Fun (
          "f",
          Var("y"),
          Var("x"),
          Fun (
              "g",
              Var("z"),
              Let (
                  Var("x"),
                  Number("6"),
                  Call("f", Var("x"))
              ),
              Call("g", Number("0")))))
#+end_src

Under dynamic scoping, we will get ~6~. With static scoping, we should
get ~5~.

Now, we make a function to create fresh integers everytime it is
called. This will help us fill in ~id~ of ~Var~ correctly.
#+begin_src python :session leroy :results none
  def make_fresh():
      i = 0
      def fresh():
          nonlocal i
          i = i + 1
          return i
      return fresh
#+end_src

Finally, the ~resolve()~ is another post-order traversal over the AST.
#+begin_src python :session leroy :results none
  def resolve(t: AST, env = None, fresh = None) -> AST:
      if env is None: env = []
      if fresh is None: fresh = make_fresh()

      match t:
          case Number(n):
              return Number(n)
          case Let(Var(x, _), e, f):
              er = resolve(e, env, fresh)
              env.append((x, i := fresh()))
              fr = resolve(f, env, fresh)
              env.pop()
              return Let(Var(x, i), er, fr)
          case Var(x, _):
              return Var(x, lookup(env, x))
          case Call(f, x):
              xr = resolve(x, env, fresh)
              return Call(f, xr)
          case Fun(f, Var(x, _), b, y):
              env.append((x, i := fresh()))
              br = resolve(b, env, fresh)
              env.pop()
              yr = resolve(y, env, fresh)
              return Fun(f, Var(x, i), br, yr)
#+end_src

Observe the AST before resolution.
#+begin_src python :session leroy :results output :exports both
  print(expr_t7ast)
#+end_src

#+RESULTS:
: Let(x=Var(v='x', i=None), e=Number(val='5'), f=Fun(f='f', x=Var(v='y', i=None), b=Var(v='x', i=None), e=Fun(f='g', x=Var(v='z', i=None), b=Let(x=Var(v='x', i=None), e=Number(val='6'), f=Call(n='f', a=Var(v='x', i=None))), e=Call(n='g', a=Number(val='0')))))

Every ~i~ field is ~None~.

Let us now look at the resolved form of our earlier AST.
#+begin_src python :session leroy :results output :exports both
  print(resolve(expr_t7ast))
#+end_src

#+RESULTS:
: Let(x=Var(v='x', i=1), e=Number(val='5'), f=Fun(f='f', x=Var(v='y', i=2), b=Var(v='x', i=1), e=Fun(f='g', x=Var(v='z', i=3), b=Let(x=Var(v='x', i=4), e=Number(val='6'), f=Call(n='f', a=Var(v='x', i=4))), e=Call(n='g', a=Number(val='0')))))

Observe how the ~x~ in the body of ~f~ gets matched to the ~x~
introduced by the outermost ~let~ through the ~i~ field in ~Var~. Now,
we can adjust the ~e()~ to lookup values based on both the variable
name and its id and obtain the correct variable as in static scoping.

** Bytecode generation

Let us generate bytecode for a calculator. First, we have to define
bytecode instructions, their format, and write a VM to execute the
bytecode. We will use a simple two-byte format:
- First byte is the opcode.
- Second byte is the immediate operand if any.

We will write the bytecode VM in C. Let us define the opcodes.
#+NAME: instruction-def
#+begin_src C
    enum op
    {
	HALT = 0,
	NOP,
	PUSH,
	POP,
	ADD,
	SUB,
	MUL,
	NEG,
    };
#+end_src

The interpreter evaluates and returns the final value on stack.
#+NAME: execute-def
#+begin_src C
  #include <stdio.h>
  #include <stdint.h>
  int execute(uint8_t *insns)
  {
    size_t ip = 0;
    int operand[100], top = 0;
  #define PUSH(x) (operand[top++] = x)
  #define POP(x) (operand[--top])	

    int l, r;
    while (1) {
      switch (insns[ip]) {
      case HALT: goto end;
      case NOP: break;
      case PUSH:
	PUSH(insns[ip+1]); break;
      case ADD:
	r = POP(); l = POP(); PUSH(l+r); break;
      case SUB:
	r = POP(); l = POP(); PUSH(l-r); break;
      case MUL:
	r = POP(); l = POP(); PUSH(l*r); break;
      case NEG:
	l = POP(); PUSH(-l); break;
      }
      ip += 2; // No control-flow.
    }
   end:
    return POP();
  #undef PUSH
  #undef POP
  }
#+end_src

Now, let us test the interpreter with some hand-crafted bytecode.
#+begin_src C :results output :exports both :noweb yes
  <<instruction-def>>
  <<execute-def>>
  int main()
  {
      uint8_t insns[] = {
	PUSH, 2,
	PUSH, 3,
	ADD , 0, // 0 is ignored.
	PUSH, 5,
	MUL , 0,
	HALT, 0,
      };
      printf("%d\n", execute(insns));
      return 0;
  }
#+end_src

#+RESULTS:
: 25

Now, we just have to take an AST for an expression into an array of
bytes and write it out to a file.
#+begin_src python :session leroy :results none
  HALT, NOP, PUSH, POP, ADD, SUB, MUL, NEG = range(8)

  def do_codegen(t: AST, code):
      match t:
          case Number(v): # Careful. I don't handle large numbers here.
              code.append(PUSH)
              code.append(int(v))
          case BinOp("+", l, r):
              do_codegen(l, code)
              do_codegen(r, code)
              code.append(ADD)
              code.append(0)
          case BinOp("-", l, r):
              do_codegen(l, code)
              do_codegen(r, code)
              code.append(SUB)
              code.append(0)
          case BinOp("*", l, r):
              do_codegen(l, code)
              do_codegen(r, code)
              code.append(MUL)
              code.append(0)
      return code

  def codegen(t):
      c = do_codegen(t, bytearray())
      c.append(HALT)
      return c
#+end_src

Let us create a sample AST and check the output bytes.
#+begin_src python :session leroy :results none
  expr_cg = BinOp ("*", BinOp("+", Number("2"), Number("3")), Number("5"))
#+end_src

And, finally:
#+begin_src python :session leroy :results output :exports both
  print(codegen(expr_cg))
#+end_src

#+RESULTS:
: bytearray(b'\x02\x02\x02\x03\x04\x00\x02\x05\x06\x00\x00')

Connecting all these pieces by appropriate file-handling is left as an
exercise.

** Bytecode execution for call and return

We will write bytecode equivalent of:
#+begin_src
  fun f(x) is x + 1 in f(42) end
#+end_src
which evaluates to 43 to illustrate CALL and RETURN.

The bytecode instructions are:
#+begin_src python :python ".compilers/.venv/bin/python" :session minf :results none
  class OC:
      JF, PUSH, ADD, CALL, RET, GET, HALT = range(1, 8)
#+end_src

The above code is then compiled into the following bytecode:
#+begin_src python :session minf :results none
  sample = [
      (OC.JF, 5), # Jump to after the function body.
      (OC.GET, "x"),
      (OC.PUSH, 1),
      (OC.ADD, None),
      (OC.RET, None),
      (OC.PUSH, 42),
      (OC.GET, "f"),
      (OC.CALL, None),
      (OC.HALT, None)
  ]
#+end_src
To simplify discussion, I keep them as Python list. The real bytecode
will be a sequence of bytes that encodes the above list.

We will discuss the bytecode evaluator first. The values in stack are
either numbers or functions. We need objects corresponding to them.
#+begin_src python :session minf :results none
  from dataclasses import dataclass

  @dataclass
  class NumObj:
      n: int

      def __repr__(self):
          return f"{self.n}"

  @dataclass
  class FunObj:
      e: int # The entry point
      a: str # The parameter name
#+end_src

For executing functions, we need call frames.
#+begin_src python :session minf :results none
  @dataclass
  class CallFrame:
      f: FunObj # The function object
      v: dict # arguments and locals
      r: int # The return address
#+end_src

After compiling the above bytecode, the compiler should create the following
function object to encode f.
#+begin_src python :session minf :results none
  f = FunObj(1, "x")
#+end_src
The code generator should create both the bytecode and a dictionary
that maps names to corresponding global objects.

#+begin_src python :session minf :results none
  @dataclass
  class Code:
      b: list # The bytecode
      o: dict # The map
#+end_src

For our sample program:
#+begin_src python :session minf :results none
  code = Code(sample, { "f" : f })
#+end_src

Now, the function that actually executes the bytecode. We return the
operand stack at the end to observe the final value.
#+begin_src python :session minf :results none
  def execute(code):
      ip = 0  # The current instruction.
      op = [] # Operand stack. Holds NumObjs or FunObjs.
      cs = [] # Call stack. Holds CallFrames.

      # We initialize the call stack with call frame of main()
      # In our example, the main() contains all code in the file
      # like in Python.
      c = CallFrame(FunObj(0, "_unused"), {}, None)
      c.v = code.o
      cs.append(c)

      while True:
          match code.b[ip]:
              case (OC.HALT, _):
                  return op
              case (OC.JF, off):
                  ip += off
              case (OC.PUSH, val):
                  op.append(NumObj(val))
                  ip += 1
              case (OC.ADD, _):
                  left = op.pop()
                  right = op.pop()
                  op.append(NumObj(left.n+right.n))
                  ip += 1
              case (OC.CALL, _):
                  f = op.pop()
                  x = op.pop()
                  c = CallFrame(f, { f.a : x }, ip+1)
                  cs.append(c)
                  ip = f.e
              case (OC.RET, _):
                  ip = cs[-1].r
                  cs.pop()
              case (OC.GET, name):
                  op.append(cs[-1].v[name])
                  ip += 1
#+end_src

Finally, we execute the code:
#+begin_src python :session minf :results output :exports both
  print(execute(code))
#+end_src

#+RESULTS:
: [43]

Let us write the function:
#+begin_src
  fun f(x) is x+1 in fun g(y) is f(y+2) in g(42) end end
#+end_src

The corresponding bytecode is:
#+begin_src python :session minf :results none
  sample2 = [
      (OC.JF, 5),
      (OC.GET, "x"),
      (OC.PUSH, 1),
      (OC.ADD, None),
      (OC.RET, None),
      (OC.JF, 7),
      (OC.GET, "y"),
      (OC.PUSH, 2),
      (OC.ADD, None),
      (OC.GET, "f"),
      (OC.CALL, None),
      (OC.RET, None),
      (OC.PUSH, 42),
      (OC.GET, "g"),
      (OC.CALL, None),
      (OC.HALT, None)
  ]
#+end_src

The new code is:
#+begin_src python :session minf :results none
  code2 = Code(sample2, { "f" : FunObj(1, "x"), "g" : FunObj(6, "y") })
#+end_src

The call to f() in g() can only find the function object for f() in
main()'s stack frame. So we need to search backwards when executing
GET. This is the only change required in the execute().
#+begin_src python :session minf :results none
  def execute2(code):
      ip = 0  # The current instruction.
      op = [] # Operand stack. Holds NumObjs or FunObjs.
      cs = [] # Call stack. Holds CallFrames.

      # We initialize the call stack with call frame of main()
      # In our example, the main() contains all code in the file
      # like in Python.
      c = CallFrame(FunObj(0, "_unused"), {}, None)
      c.v = code.o
      cs.append(c)

      while True:
          match code.b[ip]:
              case (OC.HALT, _):
                  return op
              case (OC.JF, off):
                  ip += off
              case (OC.PUSH, val):
                  op.append(NumObj(val))
                  ip += 1
              case (OC.ADD, _):
                  left = op.pop()
                  right = op.pop()
                  op.append(NumObj(left.n+right.n))
                  ip += 1
              case (OC.CALL, _):
                  f = op.pop()
                  x = op.pop()
                  c = CallFrame(f, { f.a : x }, ip+1)
                  cs.append(c)
                  ip = f.e
              case (OC.RET, _):
                  ip = cs[-1].r
                  cs.pop()
              case (OC.GET, name):
                  for i in range(len(cs)-1, -1, -1):
                      if name in cs[i].v:
                          op.append(cs[i].v[name])
                          break
                  ip += 1
#+end_src

#+begin_src python :session minf :results output :exports both
  print(execute2(code2))
#+end_src

#+RESULTS:
: [45]

The above kind of variable lookup is why in Python the following is:
#+begin_src python
  def foo():
      global x
      y = 0
      for i in range(10000):
          y += x
      return y
#+end_src
slower than:
#+begin_src python
  def foo():
      global x
      z = x
      y = 0
      for i in range(10000):
          y += z
      return y
#+end_src

** Aside: Discriminating unions

The datatype double + double with a discriminating union is not the
same as double. For example, temperature is a double+double and it
cannot be collapsed into a double as it will lose the information
whether it is in celsius or fahrenheit.
#+begin_src C
  struct temperature {
          enum { CELSIUS, FAHRENHEIT } kind;
          union {
                  double c;
                  double f;
          };
  };
#+end_src
In C, the programmer is expected to only access c when kind is
CELSIUS. This is not enforced by the compiler.

The following Python types encode the same information. Unlike C, you
can only access c when temperature is celsius.
#+begin_src python
  from dataclasses import dataclass

  class Temperature:
      pass

  @dataclass
  class Celsius(Temperature):
      c: float

  @dataclass
  class Fahrenheit(Temperature):
      f: float
#+end_src
